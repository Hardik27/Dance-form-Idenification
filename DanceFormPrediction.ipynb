{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DanceFormPrediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDsKdRF3QtSx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.inception_v3  import InceptionV3\n",
        "#from tensorflow.keras.applications.resnet50  import ResNet50\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Flatten\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EI6q7JmQ1KX"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qzsO70aQ6x_"
      },
      "source": [
        "csv_data=pd.read_csv(\"/content/gdrive/My Drive/Dance_Form_Identification/train.csv\")\n",
        "csv_data.head()\n",
        "lbl = preprocessing.LabelEncoder()\n",
        "lbl.fit(list(csv_data['target'].values))\n",
        "csv_data['target'] = lbl.transform(list(csv_data['target'].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXuwPn-pQ-Ns"
      },
      "source": [
        "count=0\n",
        "train_data=[]\n",
        "y_train=[]\n",
        "filename=\"/content/gdrive/My Drive/Dance_Form_Identification/train/\"\n",
        "\n",
        "for i in os.listdir(filename):\n",
        "  try:\n",
        "    count=count+1\n",
        "    if count%100==0:\n",
        "      print(f\"{count} Images read\")\n",
        "    image = cv2.imread(filename+i)\n",
        "    image_array = Image.fromarray(image)    \n",
        "    resize_img = image_array.resize((256 , 256))\n",
        "    train_data.append(resize_img)\n",
        "    for j in range(len(csv_data)):\n",
        "      if csv_data.iloc[j]['Image']==i:\n",
        "        y_train.append(csv_data.iloc[j]['target'])\n",
        "        break\n",
        "    print(filename+i)\n",
        "  except AttributeError:\n",
        "    print(\"Exception\")\n",
        "\n",
        "y_train=np.asarray(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqiObwhzRV02"
      },
      "source": [
        "from keras import backend as K\n",
        "import keras\n",
        "y_train=keras.utils.to_categorical(y_train,8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsODbGIVRXpm"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(VGG16(include_top=False, input_shape=(256, 256, 3)))\n",
        "# add new classifier layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(768, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(8, activation='softmax'))\n",
        "# define new model\n",
        "\n",
        "# summarize\n",
        "model.summary()\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA3qlfiJRc4o"
      },
      "source": [
        "final_data=[]\n",
        "for i in range(len(train_data)):\n",
        "  final_data.append(np.asarray(train_data[i]))\n",
        "\n",
        "train_data=np.asarray(final_data)\n",
        "train_data=train_data/255\n",
        "train_data=train_data.reshape(-1, 256,256,3)*2. -1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK_i4wKBRkvg"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtyOI9CsRobL"
      },
      "source": [
        "test=pd.read_csv(\"/content/gdrive/My Drive/Dance_Form_Identification/test.csv\")\n",
        "\n",
        "file_path=\"/content/gdrive/My Drive/Dance_Form_Identification/test/\"\n",
        "test_data=[]\n",
        "for i in range(len(test)):\n",
        "  image = cv2.imread(file_path+test.iloc[i]['Image'])\n",
        "  print(file_path+test.iloc[i]['Image'])\n",
        "  image_array = Image.fromarray(image)    \n",
        "  resize_img = image_array.resize((256 , 256))\n",
        "  test_data.append(resize_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-C9xhZFRrX4"
      },
      "source": [
        "final_data=[]\n",
        "for i in range(len(test_data)):\n",
        "  final_data.append(np.asarray(test_data[i]))\n",
        "\n",
        "test_data=np.asarray(final_data)\n",
        "test_data=test_data/255\n",
        "test_data=test_data.reshape(-1, 256,256,3)*2. -1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_umkD0xR318"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_datagenerator = ImageDataGenerator(\n",
        "        featurewise_center=False,  \n",
        "        samplewise_center=False,  \n",
        "        featurewise_std_normalization=False,  \n",
        "        samplewise_std_normalization=False,  \n",
        "        rotation_range=40,  \n",
        "        zoom_range = 0.20,  \n",
        "        width_shift_range=0.05,  \n",
        "        height_shift_range=0.075,  \n",
        "        horizontal_flip=True,  \n",
        "        vertical_flip=False) \n",
        "\n",
        "train_datagenerator.fit(train_data)\n",
        "\n",
        "train_data_final=np.array(train_data)\n",
        "print(train_data_final.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byPpJuRdR8RJ"
      },
      "source": [
        "history =model.fit_generator(\n",
        "    train_datagenerator.flow(train_data_final, y_train, batch_size=32), epochs=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQaTS2GkSChI"
      },
      "source": [
        "y_pred=model.predict(test_data)\n",
        "y_pred_classes=[]\n",
        "for i in range(len(y_pred)):\n",
        "  y_pred_classes.append(np.argmax(y_pred[i]))\n",
        "\n",
        "y_pred_classes=lbl.inverse_transform(y_pred_classes)\n",
        "test['target']=y_pred_classes\n",
        "test.to_csv(\"Submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}